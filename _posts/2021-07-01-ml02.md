---
title: "chapter01"
excerpt: ""

categories:
    - machine-learning
tags:
    - machine-learning
    - homl
use_math: true
---

_**한눈에 보는 머신러닝**_

이 장을 배우고 답할 것은
- 머신러닝은 어디서 시작하고 어디서 끝나는지
- 기계가 배운다는 것이 정확히 무엇을 의미하는지
- 머신러닝이 무엇인지, 왜 머신러닝이 필요한지

그리고 다음 내용이 전부이다.

1. 전체 머신러닝 과정을 머릿속으로 넣기
    머신러닝이 어떤 순서로 진행되는지, 머신러닝으로 할 수 있는 프로젝트는 무엇이 있는가!
2. 머신러닝의 종류
    - 지도학습과 비지도학습
    - 온라인 학습과 배치 학습
    - 사례 기반 학습과 모델 기반 학습
3. 주요 문제점 : 머신러닝 프로젝트의 작업 중 만날 수 있는 문제점들
4. 평가 : 머신러닝 시스템의 성능을 어떻게 평가할 것인가
5. 튜닝 : 성능이 낮게 나올시(오차값이 클 시) 어떻께 성능을 높일 것인가

이 장을 배우고 위의 개념을 술술 설명할 수 있게 될 것이다!

## 머신러닝에 대하여

이건 지식 습득 차원에서 살짝 정리하고 가려고 한다.

내가 보유한 세 책에서는 머신러닝을 다음과 같이 정의한다.
> **머신러닝은 일반적으로는 애플리케이션을 수정하지 않고도 데이터를 기반으로 패턴을 학습하고 결과를 예측하는 알고리즘 기법이다.** (파이썬 머신러닝 완벽 가이드)

> **정해진 코드대로 업무를 수행하는 기본적인 인공지능과는 달리 주어진 데이터를 기반으로 패턴을 파악하여 학습합니다. 학습된 모형을 이용해 예측하거나 분류하는 역할을 수행합니다.** (선형대수와 통계학으로 배우는 머신러닝)

> **머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것입니다.** (핸즈온 머신러닝)

머신러닝은 인공지능이라는 단어가 처음 등장한 1950대, 개발자가 작성한 코드대로만 일을 수행하는 지식 기반 프로그래밍에서 발전하여 사람이 일일이 업무 규칙을 작성하지 않고도 기계가 주어진 데이터를 학습하여 파악된 패턴을 통해 결과를 예측하거나 분류함으로써 특정 작업을 더 잘하도록 만드는 것이다. 더 나아가 딥러닝은 인간의 뇌 구조에서 뉴런 네트워크에서 영감을 받아 인공 신경망을 이용해 학습하고 결과를 내는 것입니다. 세 책 모두 공통적으로 나오는 중요한 단어가 '데이터'이다. 머신러닝은 데이터를 학습하기 때문에 데이터의 역할이 매우 중요하다.

### **훈련 데이터(training data)**

- 훈련 세트<sup>traing set</sup> : 머신러닝 시스템이 학습하는 데 사용하는 샘플
- 훈련 사례<sup>traing instance</sup> : 훈련 세트에서 나온 각 훈련 데이터

훈련 데이터는 다음과 같이 두 가지의 데이터로 나누어진다.

- 특성 데이터<sup>피처 데이터, feature data</sup>
- 타깃 데이터<sup>target data</sup>

예시를 들면 다음과 같이 생각해볼 수 있다.

<div style='text-align:left'>

|데이터 종류|스팸 분류|과일 분류|중고차 가격 회귀|
|--|--|--|--|
|피처 데이터|메일 샘플|맛, 모양|주행거리, 연식, 브랜드|
|타깃 데이터|소속 정보(스팸인지 아닌지)|과일 이름|타깃 데이터에 따른 중고차 가격|

</div>

### **왜 머신러닝을 사용하는가**

### 전통적인 프로그래밍 기법

전통적인 프로그래밍 기법으로 스팸 필터를 만드는 과정은 다음과 같다.

![](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-23-e1848be185a9e18492e185ae-11-40-31.png?w=625)

1. 스팸 메일에 어떤 단어들이 주로 나오는지 보고 자주 등장하는 단어 파악, 스팸을 보내는 보낸이의 이름이나 메일 주소, 본문이나 이메일에 그림이 첨부된다던지 등을 감지한다. 물론 내가!
2. 스팸을 감지하는 알고리즘을 작성하여 프로그램이 이런 패턴을 발견했을 때 스팸으로 분류하게 한다.
3. 프로그램을 테스트하고 론칭할 만큼 충분한 성능이 나올 때까지 1,2 단계를 반복한다.

_실제로 내가 건강관리협회에서 우편물 라벨링 출력시에 이 방법을 사용했다. 대변통을 받을 사람과 생애주기문진표를 받을 사람 등 규칙을 정하여 하나하나 하드코딩했었다. 그리고 잘못된 데이터가 들어올시에 규칙을 일일이 수정했어야 했고 데이터를 다시 로드하여 실행해보는 등 유지보수에서 어려움이이 많았다. 지금 생각해보면 조금만 더 나에게 그런 단순 업무를 편하게 분류할 업무 시간이 주어졌다면 머신러닝으로 라벨링 분류 작업을 개발해봤을텐데 하는 아쉬움이 남는다._

**문제가 어렵기 때문에 규칙이 점점 길고 복잡해지므로 유지 보수하기가 매우 힘들어진다.**

**Q** 그러면 머신러닝이라고 유지 보수가 어려워지지 않을까? (추후에 답변 찾아보기)

### 머신러닝 기법

![](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-23-e1848be185a9e18492e185ae-11-41-57.png?w=625)

머신러닝 기법에 기반을 둔 스팸 필터는 스팸에 자주 나타나는 패턴을 감지하여 어떤 단어와 구절이 스팸 메일을 판단하는 데 좋은 기준인지 자동으로 학습한다. 스팸 메일 발송자가 이를 알고 단어를 바꾸어 스팸을 보내어도 머신러닝은 사용자가 스팸으로 지정한 메일에서 이를 감지한다.

![](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-23-e1848be185a9e18492e185ae-11-44-33.png?w=625)

**머신러닝이 유용한 분야는 전통적인 프로그래밍으로 유지 보수가 힘든 문제 풀이나 전통적인 방식으로는 너무 복잡하거나 알려진 알고리즘이 없는 문제이다.** (예를들어 음성인식)

**데이터 마이닝** : 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견할 수 있다. 머신러닝 알고리즘이 학습한 것을 분석해보는 것이다. 가끔 예상치 못한 연관 관계나 새로운 추세가 발견되기도 한다.

### 머신러닝이 뛰어난 분야

- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 : 하나의 머신러닝 모델로 문제 해결 가능
- 전통적인 방식으로는 해결 방법이 없는 문제
- 유동적인 환경
- 복잡한 문제와 대량의 데이터에서 통찰 얻기

그럴 수 밖에 없을 것이다. 데이터를 기반으로 패턴을 감지하여 문제를 해결하는 방법이기에 하나하나 고쳐줘야 하는 업무에서 자동으로 패턴을 감지하는 방법은 도움 될 것이고 전통적인 방식으로 해결되지 않는다면 머신러닝 방법 중에서 해결책이 있을 것이다. 그리고 기술이기 때문에 새로운 데이터가 들어와도 적응 할 수 있고 머신러닝을 통해 학습된 데이터를 분석해서 또 다른 통찰을 얻을 수 있을 것이다.

### **애플리케이션 사례**

|애플리케이션|머신러닝방법|도구|
|--|--|--|
|생산라인에서 제품 이미지를 분석해 자동으로 분류하기|이미지 분류|CNN|
|뇌를 스캔하여 종양 진단하기|시멘틱 분할|CNN|
|자동으로 뉴스 기사를 분류하기|자연어처리(NLP)-텍스트 분류|RNN,CNN,트랜스포머|
|토론 포럼에서 부정적인 코멘트를 자동으로 구분하기|자연어처리(NLP)-텍스트 분류|NLP 도구|
|긴 문서를 자동으로 요약하기|자연어처리(NLP)-텍스트 요약|NLP 도구|
|챗봇 또는 개인 비서 만들기|자연어이해(NLU)|질문-대답 모듈을 포함한 NLP 컴포넌트 필요|
|다양한 성능 지표를 기반으로 회사의 내년도 수익을 예측하기|회귀|회귀 모델, 지난 성능 지표의 시퀀스를 고려한다면 RNN,CNN, 트랜스포머|
|음성 명령에 반응하는 앱을 만들기|음성 인식|RNN,CNN,트랜스포머|
|신용 카드 부정 거래 감지하기|이상치 탐지|-|
|구매 이력을 기반으로 고객을 나누고 각 집합마다 다른 마케팅 전략을 계획하기|군집|-|
|고차원의 복잡한 데이터셋을 명확ㄱ하고 의미 있는 그래프로 표현하기|데이터 시각화|차원 축소|
|과거 구매 이력을 기반으로 고객이 관심을 가질 수 있는 상품 추천하기|추천 시스템|인공 신경망|
|지능형 게임 봇 만들기|강화학습|-|


더 많은 사례 살펴보기
[머신러닝usecases](https://homl.info/usecases)

# **머신러닝 시스템의 종류**

## **머신러닝 범주 분류**

- 사람의 감독하에 훈련하는 것인지 그렇지 않은 것인지<br>
    - 지도<br>
    - 비지도<br>
    - 준지도<br>
    - 강화 학습<br>

- 실시간으로 점진적인 학습을 하는지 아닌지<br>
    - 온라인 학습<br>
    - 배치 학습<br>

- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지<br>
    - 사례 기반 학습<br>
    - 모델 기반 학습<br>

각 범주들이 섞여서 연결될 수 있다. 심층 신경망 모델을 사용해(모델 기반 학습) 스팸과 스팸이 아닌 메일(지도 학습)데이터로부터 실시간 학습(온라인 학습)이 가능하다.

### **지도 학습과 비지도 학습**

_학습하는 동안의 감독 형태나 정보량에 따라 분류_

#### **지도학습<sup>supervised learning</sup>**

![](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-23-e1848be185a9e18492e185ae-11-57-23.png?w=625)

지도학습은 라벨링된 데이터를 학습시키는 것을 의미한다. 알고리즘에 주입되는 훈련 데이터에 레이블이라는 정답이 포함되어 있다. 이 정답 부분을 타깃 데이터라고 한다. 타깃 데이터의 형태에 따라 두 가지 범주로 나뉜다. 그래서 학습 이전에 타깃 데이터의 형태를 파악하고 내가 풀고자 하는 문제가 분류 문제인지 회귀 문제인지 파악하는 것도 중요하다. 나중에 데이터의 형태를 정리해야겠다.

- 회귀<sup>regression</sup> : 연속형 숫자
- 분류<sup>classification</sup> : 범주형

|지도학습 종류|예시|
|--|--|
|분류|스팸 필터, 과일 분류|
|회귀|중고차 가격 예측|

각 알고리즘을 다른 문제에 사용할 수 있다. 회귀 알고리즘을 분류에, 분류 알고리즘을 회귀에 사용할 수도 있다.

- **k-최근접 이웃**
- **선형 회귀**
- **로지스틱 회귀**
- **서포트 벡터 머신**
- **결정 트리와 랜덤 포레스트**
- **신경망**

_제한된 볼츠만 머신같이 일부 신경망 구조는 비지도학습일 수 있다. 신경망은 심층 신뢰 신경망이나 비지도 사전훈련처럼 준지도 학습일 수도 있다. 추후에 공부해보자!_

#### **비지도 학습<sup>unsupervised learning</sup>**

![군집](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-24-e1848be185a9e1848ce185a5e186ab-12-03-43.png?w=625)

훈련 데이터에 레이블이 없다. 그래서 시스템이 아무런 도움 없이 학습해야 한다. 실제 데이터를 다루다보면 라벨링 되어 있지 않은 경우도 많이 접한다. 지도 학습의 분류는 비지도 학습에서 군집<sup>clustering</sup>이라고 한다.

- **군집**
  - k-평균
  - DBSCAN
  - 계층 군집 분석(HCA)
  - 이상치 탐지와 특이치 탐지
  - 원-클래스
  - 아이솔레이션 포레스트
- **시각화와 차원 축소**
  - 주성분 분석(PCA)
  - 커널 PCA
  - 지역적 선형 임베딩
  - t-SNE
- **연관 규칙 학습**
  - 어프라이어리
  - 이클렛

|비지도 학습 종류|예시|
|--|--|
|군집|블로그 방문자를 비슷한 그룹으로 묶는다|
|군집-계층 군집|블로그 방문자를 더 작은 그룹으로 세분화한다|
|시각화|레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D,3D 표현을 만들어준다<br>시각화된 그래프를 보고 데이터가 어떻게 조직되어 있는지 이해할 수 있고 예상하지 못한 패턴을 발견할 수도 있다.|
|차원 축소|차의 주행거리와 연식, 두 특성을 차의 마모 정도를 나타내는 하나의 특성으로 합칠 수 있다. <br>너무 많은 정보를 잃지 않으면서 데이터를 간소화한다. 그래서 상관관계가 있는 여러 특성을 하나의 특성으로 합칠 수 있는 것이다.|
|이상치 탐지|신용카드 부정 거래 방지<br>이상한 신용카드 거래를 감지하고, 제조 결함을 잡아내고, 학습 알고리즘에 주입하기 전에 데이터셋에서 이상한 값을 자동으로 제거한다|
|특이치 탐지|이상치 탐지와 비슷한 작업이지만 감지하고 싶은 모든 샘플을 제거한 '깨끗한' 훈련 세트가 필요하다|
|연관 규칙 학습|슈퍼마켓 판매 기록에 적용<br>바비큐 소스와 감자를 구매한 사람이 스테이크도 구매하는 경향이 있다 를 발견할 수 있다|

정보보안기사에서 네트워크 침임탐지가 제시된다. 트래픽 모델을 기반으로 하는 비정상 행위 탐지 방식을 사용한다. 악성코드 분석시 악성코드 행위 정보를 수집해 악성코드의 특성을 파악하여 그룹화하고 분류할 때에도 머신러닝을 사용한다.    
[정보보안에서 머신러닝](https://blog.naver.com/skinfosec2000/220937047579)


#### **준지도 학습<sup>semisuperrvised learning</sup>**

레이블이 일부만 있는 데이터를 다루는 알고리즘

예 : 구글 포토 호스팅 서비스    
대부분 준지도 학습 알고리즘은 **지도 학습과 비지도 학습의 조합**으로 이루어져 있다. **심층 신뢰 신경망**<sup>deep belief network</sup>은 **제한된 볼츠만 머신**<sup>restricted Boltzmann machine</sup>이라 불리는 비지도 학습에 기초한다. RBM이 비지도 학습 방식으로 순차적으로 훈련된 다음 전체 시스템이 지도 학습 방식으로 세밀하게 조정된다.

#### **강화 학습<sup>reinforcement learning</sup>**

환경을 관찰해서 행동을 실행하고 그 결과로 보상을 받는다. 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이락고 부르는 최상의 전략을 스스로 학습한다.

예 : 보행 로봇

### **배치 학습과 온라인 학습**    

_입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지_

#### **배치 학습**

장정보다는 단점이 많은 학습방법이라고 느껴졌다. 훈련데이터로 사용할 수 있는 전체 데이터를 모두 사용해 훈련시키는 방식이다. 시간과 자원이 많이 소모될테니 오프라인에서 수행된다. 시스템을 훈련시키고 제품 시스템에 적용하면 더 이상의 학습이 없다. 학습한 것을 단지 적용만하여 실행한다. 이를 **오프라인 학습** 이라고 한다.

**장점**    
- 방식이 간단하고 잘 작동한다.

**단점**
- 훈련 시간이 길다.   
    _전체 데이터셋을 사용해 훈련하는 데 몇 시간이 소요될 수 있다. 보통 24시간마다 또는 매주 시스템을 훈련시킨다. 생각해보면 시스템이 빠르게 변하는 데이터에 적응해야하는 방식이면 적합하지 않다._
- 많은 컴퓨팅 자원이 필요하다.(CPU, 메모리 공간, 디스크 공간, 디스크 IO, 네트워크 IO 등)    
    _대량의 데이터를 가지고 훈련 시켜야 하는데 오프라인 학습 방법으로는 매일 혹은 매주 처음부터 시스템을 새로 훈련시켜야 한다. 이를 자동화한다면 큰 비용이 발생하는건 당연하다. 데이터양이 아주 많다면 이 알고리즘을 사용하는게 불가능 할 수도 있다._
- 자원이 제한된 시스템이 사용하기에 적합하지 않다.    
    _스마트폰이나 화성 탐사 로버 같은 경우 많은 양의 훈련 데이터를 매번 나르고 학습을 위해 몇 시간씩 많은 자원을 사용한다면 심각한 문제를 일으킬것이다._

#### **온라인 학습**

![](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-24-e1848be185a9e18492e185ae-6-20-09.png?w=625)

배치 학습과는 달리 전체 훈련 데이터를 순차적으로 한 개씩 또는 미니 배치 단위로 주입하여 시스템을 훈련시키는 방식이다.    

**장점**    
- 매 학습 단계가 빠르고 비용이 적게 든다.시스템은 데이터가 도착하는 대로 즉시 학습이 가능하다.
- 많은 공간을 절약할 수 있다. 온라인 학습으로 학습이 끝난 데이터는 버리면 된다.    

**단점**
- 시스템에 나쁜 데이터가 주입되면 시스템 성능이 점진적으로 감소한다.    
  이런 위험을 줄이기 위해 시스템을 면밀히 모니터링하고 성능 감소가 감지되면 즉각 학습을 멈춰야한다. 이상치 알고리즘 같은 방식으로 데이터를 모니터링 해서 비정상 데이터를 잡아낼 수도 있다.

**적합한 시스템**    
- 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야 하는 시스템에 적합하다.
- 컴퓨팅 자원이 제한된 경우
- 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템(외부 메모리 학습)

**Q** 외부 메모리 학습    
오프라인으로 실행된다. 실시간으로 처리되는게 아니다. 왜냐 데이터가 크니까. 그렇지만 온라인 학습 **방식**으로 전체 데이터가 모두 적용될 때 까지 데이터 일부를 읽어 들이고 훈련 할 수 있다는 말이다.

**학습률**    


### **사례 기반 학습과 모델 기반 학습**
_어떻게 일반화 되는가에 따라 분류. 머신러닝의 목표! 새로운 샘플에도 좋은 예측을 만들어야(잘 작동해야)한다. 좋은 예측을 만들기 위한 방식으로 분류된다._

#### **사례 기반 학습**    

시스템이 훈련 샘플을 기억함으로써 학습하는 방법이다. **유사도** 측정 방법이 이에 포함된다.

#### **모델 기반 학습**    
샘플들의 모델을 만들어 예측에 사용하는 방법이다. 모델의 성능이 얼마나 좋은지(나쁜지)를 측정하는 방법은 다음과 같다.
- 효용 함수
- 비용 함수

모델 기반 학습에서 좋은 예측이 나오지 않는다면,
- 더 많은 특성(고용률, 건강, 대기오염)을 사용하거나
- 좋은 훈련 데이터를 더 많이 모으거나
- 더 강력한 모델(다항 회귀)을 선택

모델 훈련은 훈련 데이터에 가장 잘 맞는 그리고 새로운 데이터에 좋은 예측을 만드는 모델 파라미터를 찾기 위해 알고리즘을 실행하는 것이다.

**돈이 사람을 행복하게 만드는가**    
데이터 : oecd 웹사이트 더 나은 삶의 지표(행복), imf 웹사이트 1인당 GDP 통계(돈)    
모델 기반 : 선형 모델    
사례 기반 : K-최근접 이웃 회귀를 이용해 찾고자 하는 나라와 비슷한 GDP를 가진 나라를 찾아 세 값을 평균낸다.

[코드 제공](https://colab.research.google.com/github/ageron/handson-ml/blob/master/01_the_machine_learning_landscape.ipynb)


# **머신러닝의 주요 도전 과제**    
**나쁜 데이터**와 **나쁜 알고리즘** 이 머신 러닝에서 주요 해결해야 할 문제가 된다.

## **나쁜 데이터**

### **충분하지 않은 양의 훈련 데이터**

머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 한다.    

**믿을 수 없는 데이터의 효과**    
충분한 데이터가 주어지면 복잡한 문제는 쉬운 알고리즘에서 복잡한 알고리즘까지 비슷하게 성능을 낸다는 것이다. 시간과 돈을 **알고리즘 개발**에 쓰느냐 **데이터 개발**에 쓰느냐 사이의 트레이드오프에 대해 다시 생각해봐야한다. 복잡한 문제에서 알고리즘보다 데이터가 더 중요하다. 하지만 좋은 데이터셋을 구하는 일은 쉽거나 저렴하지 않기 때문에 알고리즘을 무시할 수는 없다.

### **대표성 없는 훈련 데이터**    
머신러닝 시스템이 좋은 예측이 가능하려면 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다.    
하지만 일반화하려는 사례들을 대표하는 훈련 세트를 항상 사용할 수는 없다.   
**샘플링 잡음<sup>sampling noise</sup>** : 샘플이 작으면 발생한다.
**샘플링 편향<sup>sampling bias</sup>** : 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못할 수 있다.

_유명한 샘플링 편향 사례로는 1936년 미국 대통령 선거에서 시행한 대규모 여론 조사이다._

### **낮은 품질의 데이터**    
훈련 데이터가 에러, 이상치<sup>outlier</sup>, 잡음으로 가득한 경우이다. 이때 훈련 데이터를 다음과 같이 정제해야한다.

- 일부 샘플이 이상치라는 게 명확하다면 **간단히 그것을 무시학거나 수동으로 잘못된 것을 고치는 것**이 좋다.
- **일부 샘플에 특성 몇 개가 빠져있다면**,    
이 특성을 모두 무시할지    
이 샘플을 무시할지    
빠진 값을 채울지    
이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지    

### **관련 없는 특성**    
_garbage in, garbage out_ 엉터리가 들어가면 엉터리가 나온다.

성공적인 머신러닝을 위해서는 훈련 데이터가 훈련에 사용할 좋은 특성을 갖춰야 하는 것이다. 다음과 같이 **특성 공학<sup>feature engineering</sup>** 작업을 한다.

- 특성 선택 : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택한다.
- 특성 추출 : 특성을 결합하여 더 유용한 특성을 만든다.
- 새로운 데이터를 수집해서 새로운 특성을 만든다.

## **나쁜 알고리즘**

### **훈련 데이터 과대적합<sup>overfitting</sup>**

과대 적합은 훈련 데이터에 있는 잡음의 양에 비해 **모델이 너무 복잡**할 때 일어난다. 쉽게 말하면, 특정 데이터 셋에만 적합되어 새로운 샘플에 대해서 성능이 낮아지는 경우이다. 그래서 주어진 데이터셋에 대해서는 오차가 없으므로 높은 성능을 보인다. 하지만 새로운 데이터 셋에 적용 한다면 훈련 데이터와는 달리 큰 오차를 보인다.   
**<해결방법>**
- 파라미터 수가 적은 모델을 선택하거나    
  훈련 데이터에 있는 특성 수를 줄이거나    
  모델에 제약<sup>regulation</sup>을 가하여 단순화시킨다    
- 훈련 데이터를 더 많이 모은다.
- 훈련 데이터의 잡음을 줄인다.

**규제<sup>regulation</sup>**    
모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것이다. 예를 들어 자유도<sup>degree of freedom</sup>을 학습 알고리즘에 부여하는 것이다. 데이터에 완벽히 맞추는 것과 일반화를 위해 단순한 모델을 유지하는 것 사이의 올바른 균형을 찾는 것이 좋다.

**하이퍼파라미터**    
학습하는 동안 적용할 규제의 양은 하이퍼파라미터가 정한다. 하이퍼파라미터는 학습 알고리즘의 파라미터이다. 그래서 학습 알고리즘으로부터 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남아 있다. **하이퍼파라미터 튜닝은 머신러닝 시스템을 구축할 때 매우 중요한 과정이다.**

### **훈련 데이터 과소적합<sup>underfitting</sup>**
**모델이 너무 단순**해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다. 훈련 데이터와 테스트 데이터 모두 큰 오차를 보인다.    
**<해결방법>**
- 모델 파라미터가 더 많은 강력한 모델을 선택한다.(복잡한 모델)
- 학습 알고리즘에 더 좋은 특성을 제공한다.(특성 공학)    
    데이터가 머신러닝으로 일반화하려는 사례들을 대표하고 있지 못하기 때문에 과소적합이 일어날 수 있다.
- 모델의 제약을 줄인다.(규제 하이퍼파라미터를 감소시킨다)    
    하이퍼파라미터가 크게 적용하고 있어 학습이 잘 안되는 것일수도 있다.

#### **편향-분산 트레이드오프**
이상적으로 연구자는 편향과 분산 모두 작은 것을 원한다. 하지만 편향이 높을수록 분산은 작아지고 편향이이 낮을수록 분산은 커지는 경향이 있다.    
편향이 높다 : 예측값들이 정답으로부터 멀리 떨어져있다. -> 주로 단순한 모델, 언더피팅    
분산이 높다 : 예측값들이 흩어져있다.(정답과 가까운지는 상관 없음) -> 주로 복잡한 모델, 오버피팅

둘다 낮게 나오는 것이 좋다.

# **머신러닝 테스트와 검증**
모델이 새로운 샘플에 얼마나 잘 일반화될지를 알아야 한다. 그래서 모델을 새로운 샘플에 실제로 적용해보는 것이다.
